{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Visualizing Sound Fall 2020",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gened1080/visualizing-sound/blob/master/Visualizing_Sound_Fall_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ_t8_Xn1aX2",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Sound (no audio/video hardware required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TMttNBJ1aX4",
        "colab_type": "text"
      },
      "source": [
        "This notebook helps you visualize the propagation of sound and its interaction with boundaries. To create the boundaries you can use an image. An edge detection algorithm is appied on the frame/image to generate the boundaries. A sound source is added to the center of the frame. The sound source can specified by providing a numerical frequency. The propagation medium can also be customized by entering sound velocity, medium density. In addition, a block can be inserted in the right half of the frame that is a different temperature (which can be entered) than the rest of the medium. \n",
        "\n",
        "The notebook relies on functions defined in the python file `VizSound_noAV.py` that we import in the following cell. If you are interested to see how the functions are implemented then open the `VizSound_noAV.py` file in another window to take a look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JffjdLuR1kop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit \n",
        "rm -rf visualizing-sound\n",
        "git clone https://github.com/gened1080/visualizing-sound.git\n",
        "pip install pydub\n",
        "pip install datasketch\n",
        "sudo apt-get install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "pip install pyaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZJaLmOI1aX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import relevant libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "import matplotlib.animation as animation\n",
        "from time import time\n",
        "import sys\n",
        "sys.path.append('/content/visualizing-sound/')\n",
        "import VizSound_noAV as vs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYuj14101aYC",
        "colab_type": "text"
      },
      "source": [
        "### Setting up the simulation\n",
        "\n",
        "In order to setup the simulation, we have to go through two main steps. The first step is provide the frame (`.jpg` image file) from which boundaries are created. The code will then perform some image processing operations on the frame, such as resizing, edge detection, noise reduction, and thresholding to generate the boundaries. The second step is to choose the properties of the sound source and the propagating medium (we call this the sound set up). There is a default sound setup that you can use or you can customize everything. For setting up the simulation, simply run the cell below and follow the instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "vVxcEcnW1aYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an object of the VSfdtd class defined in VizSound.py\n",
        "vs_obj = vs.VSfdtd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiZf7uP01aYH",
        "colab_type": "text"
      },
      "source": [
        "### Running the simulation\n",
        "\n",
        "This code simulates sound propagation by solving the [acoustic wave equation](https://en.wikipedia.org/wiki/Acoustic_wave_equation#Equation) using a method known as the [finite-difference time-domain](https://en.wikipedia.org/wiki/Finite-difference_time-domain_method) (FDTD). The FDTD method was originally estalished for solving the electromagnetic wave equation, however one can make a direct correspondence between the electromagnetic and acoustic wave equations and apply the same method. In brief, the FDTD method converts the coupled partial differential equations into algebraic equations that are solved in time and space. Running the simulation essentially means running the loop in which these algebraic equations are solved. The results (sound pressure) are displayed in the animation below the cell. To run the simulation all you have to do is run the cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raJ1pzpf1aYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup a figure \n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_subplot(111)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDKFYkrtypMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function runs the FDTD simulation and generates the frames to create the animation\n",
        "def propagate_sound(i):\n",
        "    global vs_obj, ax, fig\n",
        "    vs_obj.fdtd_update()\n",
        "    vs_obj.source(i)\n",
        "    if vs.bflag == \"o\":\n",
        "        vs_obj.boundary()\n",
        "    imgdisp = vs_obj.img_cap + vs_obj.pr + vs_obj.mbndry\n",
        "    ax.clear()\n",
        "    imsound = ax.pcolormesh(imgdisp, cmap=\"gray\", vmin=-1, vmax=1)\n",
        "    return imsound"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDtq-PFQzLcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choosing an appropriate interval between frames based on dt and \n",
        "# the time to animate one step\n",
        "t0 = time()\n",
        "propagate_sound(0)\n",
        "t1 = time()\n",
        "interval = 1000 * vs_obj.dt - (t1 - t0)\n",
        "# setup animatation\n",
        "vis_sound = animation.FuncAnimation(fig, propagate_sound, frames=400, interval=interval, blit=False, repeat=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz63dClr0Bdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and run the animation\n",
        "vis_sound"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbUbuTig2XIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}